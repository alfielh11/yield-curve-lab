{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yield Curve Lab: Exploration Notebook\n",
    "\n",
    "This notebook is designed for people who just cloned the repo and want a guided tour of the outputs.\n",
    "\n",
    "You will:\n",
    "- verify required files exist,\n",
    "- inspect the US Treasury yield curve history,\n",
    "- review Nelson-Siegel fitted parameters,\n",
    "- review PCA factor structure,\n",
    "- inspect scenario and risk outputs.\n",
    "\n",
    "If outputs are missing, run scripts `01` to `06` first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Setup and File Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(\"default\")\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "pd.set_option(\"display.width\", 140)\n",
    "\n",
    "PROJECT_ROOT = Path(\".\").resolve().parent\n",
    "DATA_PROCESSED = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "\n",
    "print(\"Project root:\", PROJECT_ROOT)\n",
    "print(\"Processed data path:\", DATA_PROCESSED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_outputs = [\n",
    "    \"yield_curve_long.parquet\",\n",
    "    \"yield_curve_wide.parquet\",\n",
    "    \"nelson_siegel_params.parquet\",\n",
    "    \"pca_loadings.parquet\",\n",
    "    \"pca_scores.parquet\",\n",
    "    \"pca_explained_variance.parquet\",\n",
    "    \"scenario_summary.parquet\",\n",
    "    \"scenario_curves_parametric.parquet\",\n",
    "    \"risk_metrics.csv\",\n",
    "]\n",
    "\n",
    "status_rows = []\n",
    "for name in required_outputs:\n",
    "    path = DATA_PROCESSED / name\n",
    "    status_rows.append({\"file\": name, \"exists\": path.exists()})\n",
    "\n",
    "status_df = pd.DataFrame(status_rows)\n",
    "display(status_df)\n",
    "\n",
    "missing = status_df.loc[~status_df[\"exists\"], \"file\"].tolist()\n",
    "if missing:\n",
    "    print(\"\\nMissing outputs detected. Run scripts 01 -> 06 before continuing:\")\n",
    "    for i in range(1, 7):\n",
    "        print(f\"python scripts/{i:02d}_*.py\")\n",
    "else:\n",
    "    print(\"\\nAll required outputs are present.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Load Core Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df = pd.read_parquet(DATA_PROCESSED / \"yield_curve_long.parquet\")\n",
    "wide_df = pd.read_parquet(DATA_PROCESSED / \"yield_curve_wide.parquet\")\n",
    "\n",
    "long_df[\"date\"] = pd.to_datetime(long_df[\"date\"])\n",
    "wide_df.index = pd.to_datetime(wide_df.index)\n",
    "wide_df = wide_df.sort_index().sort_index(axis=1)\n",
    "\n",
    "print(\"Long shape:\", long_df.shape)\n",
    "print(\"Wide shape:\", wide_df.shape)\n",
    "print(\"Date range:\", wide_df.index.min().date(), \"to\", wide_df.index.max().date())\n",
    "\n",
    "display(long_df.head())\n",
    "display(wide_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latest curve plot (percent)\n",
    "latest_curve = wide_df.iloc[-1]\n",
    "x = latest_curve.index.astype(float)\n",
    "y = latest_curve.values * 100.0\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4.5))\n",
    "ax.plot(x, y, marker=\"o\")\n",
    "ax.set_title(f\"Latest Treasury Curve ({wide_df.index[-1].date()})\")\n",
    "ax.set_xlabel(\"Maturity (Years)\")\n",
    "ax.set_ylabel(\"Yield (%)\")\n",
    "ax.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Daily Yield Changes (for PCA intuition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = wide_df.diff().dropna(how=\"all\").interpolate(limit_direction=\"both\").dropna(how=\"any\")\n",
    "delta_bp = delta * 10_000.0\n",
    "\n",
    "print(\"Delta shape:\", delta_bp.shape)\n",
    "display(delta_bp.describe().T[[\"mean\", \"std\", \"min\", \"max\"]].round(3))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 4.5))\n",
    "for maturity in [2.0, 5.0, 10.0, 30.0]:\n",
    "    if maturity in delta_bp.columns:\n",
    "        ax.plot(delta_bp.index, delta_bp[maturity], label=f\"{maturity:g}Y\")\n",
    "ax.set_title(\"Daily Yield Changes (bp)\")\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"Change (bp)\")\n",
    "ax.grid(alpha=0.3)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Nelson-Siegel Parameter Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_params = pd.read_parquet(DATA_PROCESSED / \"nelson_siegel_params.parquet\")\n",
    "ns_params.index = pd.to_datetime(ns_params.index)\n",
    "\n",
    "display(ns_params.tail())\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 6), sharex=True)\n",
    "axes = axes.flatten()\n",
    "for ax, col in zip(axes, [\"beta0\", \"beta1\", \"beta2\", \"tau\"]):\n",
    "    ax.plot(ns_params.index, ns_params[col])\n",
    "    ax.set_title(col)\n",
    "    ax.grid(alpha=0.3)\n",
    "fig.suptitle(\"Nelson-Siegel Parameter History\", y=1.02)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) PCA Factors and Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings = pd.read_parquet(DATA_PROCESSED / \"pca_loadings.parquet\")\n",
    "scores = pd.read_parquet(DATA_PROCESSED / \"pca_scores.parquet\")\n",
    "explained = pd.read_parquet(DATA_PROCESSED / \"pca_explained_variance.parquet\")\n",
    "scores.index = pd.to_datetime(scores.index)\n",
    "\n",
    "display(explained)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4.5))\n",
    "for pc in loadings.index:\n",
    "    ax.plot(loadings.columns.astype(float), loadings.loc[pc], marker=\"o\", label=pc)\n",
    "ax.set_title(\"PCA Loadings by Maturity\")\n",
    "ax.set_xlabel(\"Maturity (Years)\")\n",
    "ax.set_ylabel(\"Loading\")\n",
    "ax.grid(alpha=0.3)\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4.5))\n",
    "for col in scores.columns:\n",
    "    ax.plot(scores.index, scores[col], label=col)\n",
    "ax.set_title(\"PCA Factor Scores\")\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"Score\")\n",
    "ax.grid(alpha=0.3)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Scenario Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_summary = pd.read_parquet(DATA_PROCESSED / \"scenario_summary.parquet\")\n",
    "display(scenario_summary.groupby(\"method\")[[\"y10_change_bp\", \"s2s10_change_bp\"]].describe().round(2))\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(11, 4.2))\n",
    "axes[0].hist(scenario_summary[\"y10_change_bp\"], bins=40)\n",
    "axes[0].set_title(\"10Y Yield Change Distribution\")\n",
    "axes[0].set_xlabel(\"bp\")\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "axes[1].hist(scenario_summary[\"s2s10_change_bp\"], bins=40)\n",
    "axes[1].set_title(\"2s10s Spread Change Distribution\")\n",
    "axes[1].set_xlabel(\"bp\")\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Portfolio Risk Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_metrics = pd.read_csv(DATA_PROCESSED / \"risk_metrics.csv\")\n",
    "display(risk_metrics)\n",
    "\n",
    "print(\"Interpretation:\")\n",
    "print(\"- VaR_95 is the loss level exceeded only 5% of the time (under these scenarios).\")\n",
    "print(\"- ES_95 is the average loss in that worst 5% tail.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Re-run Pipeline Commands (PowerShell)\n",
    "\n",
    "Use these commands from the project root:\n",
    "\n",
    "```powershell\n",
    "python scripts/01_download_and_plot_curve.py\n",
    "python scripts/02_build_history_dataset.py --n-days 252\n",
    "python scripts/03_fit_nelson_siegel.py\n",
    "python scripts/04_pca_factors.py --n-components 3\n",
    "python scripts/05_generate_scenarios.py --n-scenarios 1000 --seed 42\n",
    "python scripts/06_portfolio_risk_demo.py\n",
    "pytest -q\n",
    "```\n",
    "\n",
    "Tip: Because `data/` is gitignored, each user should run the pipeline locally to generate outputs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
